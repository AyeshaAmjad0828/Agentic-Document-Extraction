{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "import numpy as np\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataExtractionEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Gymnasium environment for the Agentic Data Extraction process.\n",
    "    The agent interacts with the environment to improve data extraction accuracy.\n",
    "    Observations include Exact Match Score and Similarity Score.\n",
    "    Actions represent adjustments to prompt engineering strategies.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DataExtractionEnv, self).__init__()\n",
    "        self.action_space = gym.spaces.Discrete(5)  # 5 possible prompt adjustments\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32)  # [Exact Match, Similarity]\n",
    "        self.state = None\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Simulate feedback based on action\n",
    "        exact_match_score = self.state[0] + np.random.uniform(-0.05, 0.1)\n",
    "        similarity_score = self.state[1] + np.random.uniform(-0.05, 0.1)\n",
    "\n",
    "        # Reward: product of scores minus a penalty for suboptimal actions\n",
    "        reward = exact_match_score * similarity_score - abs(action - 2) * 0.05\n",
    "\n",
    "        # Update state\n",
    "        self.state = np.clip([exact_match_score, similarity_score], 0, 1)\n",
    "\n",
    "        # Check if task is complete\n",
    "        done = bool(self.state[0] >= 0.95 and self.state[1] >= 0.95)\n",
    "\n",
    "        # Additional info\n",
    "        info = {}\n",
    "        return np.array(self.state), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.random.uniform(0.2, 0.4, size=(2,))\n",
    "        return np.array(self.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymnasiumAgent:\n",
    "    @classmethod\n",
    "    def get_docs(cls, env):\n",
    "        return env.unwrapped.__doc__\n",
    "\n",
    "    def __init__(self, model, env):\n",
    "        self.model = model\n",
    "        self.env = env\n",
    "        self.docs = self.get_docs(env)\n",
    "\n",
    "        self.instructions = \"\"\"\n",
    "Your goal is to maximize your return, i.e., the sum of the rewards you receive.\n",
    "I will give you an observation, reward, termination flag, truncation flag, and the return so far, formatted as:\n",
    "\n",
    "Observation: <observation>\n",
    "Reward: <reward>\n",
    "Termination: <termination>\n",
    "Truncation: <truncation>\n",
    "Return: <sum_of_rewards>\n",
    "\n",
    "You will respond with an action, formatted as:\n",
    "\n",
    "Action: <action>\n",
    "\n",
    "where you replace <action> with your actual action.\n",
    "\"\"\"\n",
    "        self.action_parser = RegexParser(\n",
    "            regex=r\"Action: (.*)\", output_keys=[\"action\"],\n",
    "        )\n",
    "\n",
    "    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n",
    "    def get_action(self, observation, total_reward, terminated):\n",
    "        \"\"\"Retry logic for getting action from the model.\"\"\"\n",
    "        response = self.model([\n",
    "            SystemMessage(content=self.instructions),\n",
    "            HumanMessage(content=f\"Observation: {observation}\\nReward: {total_reward}\\nTermination: {terminated}\\nTruncation: False\\nReturn: {total_reward}\")\n",
    "        ])\n",
    "\n",
    "        return int(self.action_parser.parse(response.content)['action'])\n",
    "\n",
    "    def interact(self):\n",
    "        observation, _ = self.env.reset()\n",
    "        terminated = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not terminated:\n",
    "            print(f\"Observation: {observation}\")\n",
    "\n",
    "            try:\n",
    "                action = self.get_action(observation, total_reward, terminated)\n",
    "            except Exception as e:\n",
    "                print(f\"Action retrieval failed after retries: {e}\")\n",
    "                break\n",
    "\n",
    "            # Perform action in the environment\n",
    "            observation, reward, terminated, _ = self.env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            print(f\"Action: {action}, Reward: {reward}, Total Return: {total_reward}\")\n",
    "\n",
    "        print(\"Task completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 0.3875411494014725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayesha.amjad\\AppData\\Local\\Temp\\ipykernel_31928\\1669762447.py:34: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = self.model([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Reward: 0.07086501457090794, Total Return: 0.07086501457090794\n",
      "Observation: [0.44220968 0.38638913]\n",
      "Action retrieval failed after retries: RetryError[<Future at 0x16b35f59110 state=finished raised ValueError>]\n",
      "Task completed successfully!\n"
     ]
    }
   ],
   "source": [
    "env = DataExtractionEnv()\n",
    "agent = GymnasiumAgent(model=ChatOpenAI(temperature=0.2), env=env)\n",
    "agent.interact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
